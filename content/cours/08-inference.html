---
title: ""
linktitle: "Inférence bayésienne"
date: "2020-11-30"
read_date: "2020-12-01"
menu:
  cours:
    parent: "II Modélisation Bayésienne"
    weight: 5
type: docs
bibliography: "../../static/bib/references.bib"
csl: "../../static/bib/chicago-fullnote-bibliography-no-bib.csl"
slides: "01-slides"
output:
  blogdown::html_page:
    toc: false
---



<div id="inférence-bayésienne" class="section level2">
<h2>Inférence bayésienne</h2>
<p>Une fois la modélisation bayésienne terminée, on dispose de la distribution <em>a posteriori</em> (obtenue grâce au choix de la distribution <em>a priori</em>, du modèle d’échantillonnage et des données observées). Cette distribution contient l’ensemble de l’information sur <span class="math inline">\(\theta\)</span> conditionnellement au modèle et aux données. On peut néanmoins s’intéresser à des résumés de cette distribution, par exemple à un paramètre central de cette distribution tel que l’espérance, le mode ou encore la médiane (ces derniers sont analogues aux estimateurs ponctuels obtenus par l’analyse fréquentiste), où à des intervalles de valeurs dont la probabilité <em>a posteriori</em> est forte.</p>
<div id="théorie-de-la-décision" class="section level3">
<h3>Théorie de la décision</h3>
<p>La théorie de la décision statistique est généralement utilisée dans un contexte d’estimation d’un paramètre inconnu <span class="math inline">\(\theta\)</span>. La décision concerne alors le choix d’un estimateur ponctuel <span class="math inline">\(\widehat{\theta}\)</span>. Afin de déterminer le <span class="math inline">\(\widehat{\theta}\)</span> optimal, on définit une <strong>fonction de coût</strong> (à valeur dans <span class="math inline">\([0, +\infty[\)</span>) représentant la pénalité associée au choix d’un <span class="math inline">\(\widehat{\theta}\)</span> particulier (c’est-à-dire à la décision associée). Afin de déterminer le <span class="math inline">\(\widehat{\theta}\)</span> optimal (c’est-à-dire la décision optimale) on va vouloir minimiser la fonction de coût choisie. À noter qu’un grand nombre de fonctions de coût différentes sont possibles, et que chacune d’entre elle résulte en un estimateur ponctuel optimal différent et donc une décision optimale spécifique.</p>
</div>
<div id="lespérance-a-posteriori" class="section level3">
<h3>L’espérance <em>a posteriori</em></h3>
<p>L’espérance <em>a posteriori</em> est définie par :
<span class="math display">\[\mu_P = \mathbb{\mathbb{E}}(\theta|\boldsymbol{y}) = \mathbb{E}_{\theta|\boldsymbol{y}}(\theta)\]</span>
À noter que le calcul de cette espérance <em>a posteriori</em> n’est pas toujours facile car il suppose le calcul d’une intégrale…</p>
<p>D’un point de vue fréquentiste, c’est l’estimateur qui a la plus petite variance <em>a posteriori</em> parmi tous les estimateurs sans biais. En effet, pour un estimateur sans biais de <span class="math inline">\(\theta\)</span> quelconque <span class="math inline">\(\hat{\theta}\)</span> :
<span class="math display">\[\begin{align*}
\mathbb{E}_{\theta|\boldsymbol{y}}(\hat{\theta} - \theta)^2 &amp; = \mathbb{E}_{\theta|\boldsymbol{y}}(\theta-\mu_P +\mu_P -\hat{\theta})^2\\
 &amp; = \mathbb{E}_{\theta|\boldsymbol{y}}(\theta-\mu_P)^2 +\mathbb{E}_{\theta|\boldsymbol{y}}(\mu_P -\hat{\theta})^2\; ^*\\
 &amp; \geq \mathbb{E}_{\theta|\boldsymbol{y}}(\theta-\mu_P)^2\\
 &amp; ^*\text{ car } \theta \text{ est constant du point de vue fréquentiste et par linéarité de l&#39;espérance}
\end{align*}\]</span>
<span class="math inline">\(\mu_P\)</span> minimise alors l’expression ci-dessus en annulant le deuxième terme (on remarque que l’erreur en moyenne quadratique est égale à la variance, puisque l’on s’intéressent aux estimateurs sans biais).</p>
</div>
<div id="le-maximum-a-posteriori" class="section level3">
<h3>Le maximum <em>a posteriori</em></h3>
<p>Le maximum a été beaucoup utilisé, surtout car il est plus facile (ou en tout cas moins difficile) à calculer. En effet, il ne requiert aucun calcul d’intégrale, mais une simple maximisation de <span class="math inline">\(f(\boldsymbol{y}|\theta)\pi(\theta)\)</span> (car le dénominateur <span class="math inline">\(f(\boldsymbol{y})\)</span> ne dépend pas de <span class="math inline">\(\theta\)</span>). L’estimateur du mode s’appelle le <strong>maximum <em>a posteriori</em></strong> (souvent noté <strong>MAP</strong>).</p>
<p>Le MAP peut être vu comme une régularisation de l’estimateur du maximum de vraisemblance, dont il est proche.</p>
</div>
<div id="la-médiane-a-posteriori" class="section level3">
<h3>La médiane <em>a posteriori</em></h3>
<p>La médiane est également un résumé possible de la distribution <em>a posteriori</em>. Comme son nom l’indique, il s’agit de la médiane de <span class="math inline">\(p(\theta | \boldsymbol(y))\)</span>. Il s’agit de l’estimateur ponctuel optimal au sens de l’erreur absolue (fonction de coût linéaire).</p>
</div>
<div id="lintervalle-de-crédibilité" class="section level3">
<h3>L’intervalle de crédibilité</h3>
<p>Finalement on peut définir un ensemble de valeurs ayant une forte probabilité <em>a posteriori</em>. Un tel ensemble est appelé <strong>ensemble de crédibilité</strong>. Si la loi <em>a posteriori</em> est unimodale, un tel ensemble est un intervalle. Par exemple, un <strong>intervalle de crédibilité à 95%</strong> est un intervalle <span class="math inline">\([t_{inf};t_{sup}]\)</span> tel que <span class="math inline">\(\textstyle\int_{t_{inf}}^{t_{sup}} p(\theta|\boldsymbol{y})\,\text{d}\theta = 0.95\)</span>. En général on est intéressé par l’intervalle de crédibilité à 95% le plus étroit possible (<em>Highest Density Interval</em>).</p>
<p>On rappelle ici l’interprétation d’un intervalle de confiance fréquentiste au niveau 95%, qui s’interprète comme suit, par rapport à l’ensemble des intervalles de ce niveau qu’on aurait pu observer : …</p>
<blockquote>
<p>…<br />
…<br />
…</p>
</blockquote>
<p>⚠️
 on ne peut pas interpréter une réalisation d’un intervalle de confiance en terme probabiliste ! C’est une erreur qui est souvent commise… L’intervalle de crédibilité s’interprète lui bien plus naturellement, comme un intervalle qui a 95% de chance de contenir <span class="math inline">\(\theta\)</span> (pour un niveau de 95%, évidemment).</p>
</div>
<div id="distribution-prédictive" class="section level3">
<h3>Distribution prédictive</h3>
<p>La <strong>distribution prédictive</strong> (appelée parfois <em>posterior predictive</em>) est définie comme la distribution d’une nouvelle observation <span class="math inline">\(Y_{n+1}\)</span> sachant les observations de l’échantillon. Elle se calcule comme la distribution de <span class="math inline">\(Y_{n+1}\)</span> sachant <span class="math inline">\(\boldsymbol{y}\)</span>, marginalement par rapport à <span class="math inline">\(\theta\)</span>. <span class="math inline">\(f_{Y_{n+1}} (y|\boldsymbol{y}) = \int f_{Y_{n+1}}(y|\theta)p(\theta|\boldsymbol{y}) \,\text{d}\theta\)</span>. Le calcul se fait ainsi :
<span class="math display">\[\begin{align*}
f_{Y_{n+1}}(y|\boldsymbol{y}) &amp;= \int f_{Y_{n+1}} (y, \theta|\boldsymbol{y}) \,\text{d}\theta\\
  &amp;= \int f_{Y_{n+1}} (y|\theta, \boldsymbol{y})p(\theta|\boldsymbol{y}) \,\text{d}\theta\\
  &amp;= \int f_{Y_{n+1}} (y|\theta)p(\theta|\boldsymbol{y}) \,\text{d}\theta
\end{align*}\]</span>
On remarque le lien entre cette formule et celle de la distribution marginale : <span class="math inline">\(f_Y(y) = \textstyle \int f_Y(y|\theta)\pi(\theta) \,\text{d}\theta\)</span>, qui peut être vue comme un cas particulier de la distribution prédictive quand il n’y a pas d’information apportée par l’échantillon observé. On note également la différence avec l’approche fréquentiste où l’on estime d’abord <span class="math inline">\(\theta\)</span> par <span class="math inline">\(\hat{\theta}\)</span>, et l’on remplace <span class="math inline">\(\theta\)</span> par <span class="math inline">\(\hat{\theta}\)</span> pour obtenir la distribution prédictive : <span class="math inline">\(f_{Y_{n+1}} (y|\hat{\theta})\)</span>.</p>
<div class="Exercise">
<p><em>Exercice</em> : calculer la distribution prédictive sur l’exemple historique du sexe à la naissance pour un <em>a priori</em> uniforme.</p>
</div>
</div>
<div id="propriétés-asymptotiques-et-fréquentistes-de-la-distribution-a-posteriori" class="section level3">
<h3>Propriétés asymptotiques – et fréquentistes – de la distribution <em>a posteriori</em></h3>
<div id="théorème-de-convergence-de-doob" class="section level4">
<h4>Théorème de convergence de Doob</h4>
<p>Un résultat très intéressant est le comportement asymptotique de la distribution <em>a posteriori</em> sous certaines hypothèses (cas <span class="math inline">\(iid\)</span>, densités dérivables trois fois, existence de moments d’ordre 2). Il y a un premier résultat, le <strong>théorème de convergence de Doob</strong>, qui assure que la distribution <em>a posteriori</em> se concentre vers la vraie valeur du paramètre quand <span class="math inline">\(n \rightarrow \infty\)</span>. On peut le noter (convergence en Loi) :
<span class="math display">\[p(\theta|\boldsymbol{y}_n) \overset{\mathcal{L}}{\rightarrow} \delta_{\theta^*}\]</span></p>
<p><img src="/cours/08-inference_files/figure-html/Posterior%20density%20Uniform-1.png" width="95%" /></p>

</div>
<div id="théorème-de-bernstein-von-mises" class="section level4">
<h4>Théorème de Bernstein-von Mises</h4>
<p>Un résultat plus riche caractérise la distribution asymptotique de <span class="math inline">\(\theta\)</span> : le <strong>Théorème de Bernstein-von Mises</strong> (aussi appelé <strong>Théorème limite central bayésien</strong>). Pour <span class="math inline">\(n\)</span> grand la distribution <em>a posteriori</em> <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> peut être approximée par une loi normale ayant pour espérance le mode <span class="math inline">\(\hat{\theta}\)</span> et pour variance l’inverse de la Hessienne (dérivée seconde) de <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> par rapport à <span class="math inline">\(\theta\)</span>, pris au mode <span class="math inline">\(\theta\)</span>.</p>
<p>Ci-dessous une démonstration heuristique, grâce à un développement limité de <span class="math inline">\(\log(p(\theta|\boldsymbol{y}))\)</span> autour du mode <span class="math inline">\(\hat{\theta}\)</span> donne :
<span class="math display">\[ \log(p(\theta|\boldsymbol{y})) = \log(p(\hat{\theta}|\boldsymbol{y})) + \frac{1}{2}(\theta-\hat{\theta})^T\left[\frac{\partial^2\log(p(\theta|\boldsymbol{y}))}{\partial \theta^2}\right]_{\theta=\hat{\theta}}(\theta-\hat{\theta}) + \dots\]</span>
On note que le terme linéaire (omis ci-dessus) est nul, puisque la dérivée de <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> est nulle en son mode (<span class="math inline">\(\hat{\theta}\)</span>). Le premier terme est lui constant en <span class="math inline">\(\theta\)</span>. Donc, en négligeant les termes suivants du développement, le logarithme de <span class="math inline">\(p(\theta|\boldsymbol{y})\)</span> est égal au logarithme d’une densité gaussienne d’espérance <span class="math inline">\(\hat{\theta}\)</span> et de variance <span class="math inline">\(I(\hat{\theta})^{-1}\)</span> (où <span class="math inline">\(\textstyle I(\theta) = \left.\frac{\partial^2\log(p(\theta|\boldsymbol{y}))}{\partial \theta^2}\right|_{\theta=\hat{\theta}}\)</span>), et l’on donc peut écrire l’approximation :
<span class="math display">\[p(\theta|\boldsymbol{y}) \approx \mathcal{N}(\hat{\theta}, I(\hat{\theta})^{-1})\]</span></p>
<p>Ce résultat a une double importance : </p>
<ul>
<li><p>il peut être utilisé pour expliquer pourquoi les <strong>procédures bayésienne et fréquentiste basées sur le maximum de vraisemblance</strong> donnent, pour <span class="math inline">\(n\)</span> grand, des résultats très voisins. Ainsi, en dimension 1, l’intervalle de crédibilité asymptotique est : <span class="math inline">\([\hat{\theta} \pm 1.96 \sqrt{I(\hat{\theta})^{-1}}]\)</span>, et si on le compare à l’intervalle de confiance fréquentiste construit à partir de la loi asymptotique de l’estimateur : <span class="math inline">\([\hat{\theta}_{MLE} \pm 1.96 \sqrt{I(\hat{\theta}_{MLE})^{-1}}]\)</span> (où <span class="math inline">\(I(\hat{\theta}_{MLE}\)</span>) est ici la matrice d’information de Fisher observée, et correspond à la définition précédente pour des lois <em>a priori</em> uniformes), on note qu’ils sont tous les deux identiques (pour un <em>a priori</em> uniforme). Pour ces lois <em>a priori</em>, on note que l’on a aussi <span class="math inline">\(\hat{\theta} = \hat{\theta}_{MLE}\)</span> (et même si on ne prend pas des <em>a priori</em> uniformes, les estimateurs et intervalles sont très proches, puisque le poids de la loi <em>a priori</em> devient négligeable quand <span class="math inline">\(n \rightarrow \infty\)</span>). L’interprétation théorique de ces intervalles reste évidemment différente.</p></li>
<li><p>il signifie que l’on peut <strong>approximer la distribution <em>a posteriori</em> par une loi normale</strong>, dont on peut calculer l’espérance et la variance simplement à l’aide du MAP, et permet donc de faciliter les calculs numériques de l’inférence bayésienne.</p></li>
</ul>
</div>
</div>
</div>
