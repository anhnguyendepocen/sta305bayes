---
title: "Exercice 3 : Algorithme(s) de Metropolis-Hastings pour l'exemple historique (modèle Beta-Bernoulli)"
linktitle: "Exercice 3 : Metropolis-Hastings"
date: "2020-06-18"
read_date: "2020-06-18"
menu:
  practicals:
    parent: "TP"
    weight: 3
type: docs
output:
  blogdown::html_page:
    toc: false
    number_sections: false
bibliography: "../../static/bib/references.bib"
---



<p>En reprenant l’exemple historique, programmer un algorithme de Metropolis-Hastings indépendant pour estimer la loi <em>a posteriori</em> du paramètre <span class="math inline">\(\theta\)</span> (la probabilité d’avoir une fille à la naissance). On prendra comme loi instrumentale la loi <em>a priori</em> de <span class="math inline">\(\theta\)</span>, et on utilisera dans un premier temps un <em>a priori</em> uniforme. On considerera les <span class="math inline">\(493\,472\)</span> naissances observées à Paris entre 1745 et 1770, dont <span class="math inline">\(241\,945\)</span> furent des filles.</p>
<ol style="list-style-type: decimal">
<li><p>Programmer une fonction calculant le numérateur du posterior, dont on rappel l’expression : <span class="math inline">\(p(\theta|n,S)\propto\theta^S(1-\theta)^{n-S}\)</span> où <span class="math inline">\(S = 241\,945\)</span> et <span class="math inline">\(n = 493\,472\)</span> (prévoir un argument permettant de renvoyer - ou non - le logarithme).</p>
<pre class="r"><code>post_num_hist &lt;- function(theta, log = FALSE) {

    # data
    n &lt;- 493472
    S &lt;- 241945

    if (log) {
        num &lt;- S * log(theta) + (n - S) * log(1 - theta)
    } else {
        num &lt;- theta^S * (1 - theta)^(n - S)
    }
    return(num)
}</code></pre>
<pre class="r"><code>post_num_hist(0.2, log = FALSE)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>post_num_hist(0.6, log = FALSE)</code></pre>
<pre><code>## [1] 0</code></pre>
<pre class="r"><code>post_num_hist(0.2, log = TRUE)</code></pre>
<pre><code>## [1] -445522.1</code></pre>
<pre class="r"><code>post_num_hist(0.6, log = TRUE)</code></pre>
<pre><code>## [1] -354063.6</code></pre></li>
<li><p>Programmer l’algorithme de Metropolis-Hastings correspondant qui renvoie un vecteur de taille <span class="math inline">\(n\)</span> échantillonné selon la loi <em>a posteriori</em> (on utilisera l’a priori — la loi Uniforme — comme loi instrumentale). On prendra soin également de renvoyer le vecteur des probabilités d’acceptation. Que se passe-t-il si l’on ne calcule <strong>PAS</strong> cette probabilité d’acceptation dans l’échelle <em>log</em> ?</p>
<pre class="r"><code>monMH &lt;- function(niter, post_num) {

    x_save &lt;- numeric(length = niter)  # sauver les valeurs échantillonées - initialisation d&#39;un vecteur de 0s de taille niter
    alpha &lt;- numeric(length = niter)  # sauver les probabilités d&#39;acceptation - initialisation d&#39;un vecteur de 0s de taille niter

    # initialisation de x0
    x &lt;- runif(n = 1, min = 0, max = 1)

    for (t in 1:niter) {

        # proposer une valeur a partir de la loi instumentale (a priori uniforme)
        y &lt;- runif(n = 1, min = 0, max = 1)

        # calculer la probabilité d&#39;acceptation-rejet
        alpha[t] &lt;- min(1, exp(post_num(y, log = TRUE) - post_num(x, log = TRUE)))
        # message(&#39;alpha :&#39;, alpha) #permet d&#39;afficher alpha

        # etape d&#39;acceptation-rejet
        u &lt;- runif(1)
        if (u &lt;= alpha[t]) {
            x_save[t] &lt;- y
        } else {
            x_save[t] &lt;- x
        }

        # mise-à-jour de la valeur courante x
        x &lt;- x_save[t]
    }
    return(list(theta = x_save, alpha = alpha))
}</code></pre></li>
<li><p>Comparer la densité a posteriori obtenu avec l’algorithme M-H sur 2000 itérations à celle théorique. On prendra soin d’enlever les 500 premières itérations afin d’obtenir la convergence de la chaîne de Markov. Commenter ces résultats, notamment au vu des différentes probabilités d’acceptation calculées au cours de l’algorithme et des différentes valeurs échantillonnées pour <span class="math inline">\(\theta\)</span>.</p>
<pre class="r"><code>sampleMH &lt;- monMH(2000, post_num = post_num_hist)

# evaluation graphique
par(mfrow = c(2, 2))
plot(density(sampleMH$theta[-c(1:500)]), col = &quot;red&quot;, xlim = c(0, 1), ylab = &quot;Densité de probabilité a posteriori&quot;, 
    xlab = expression(theta), main = &quot;&quot;)
curve(dbeta(x, 241945 + 1, 251527 + 1), from = 0, to = 1, n = 10000, add = TRUE)
legend(&quot;topright&quot;, c(&quot;M-H&quot;, &quot;théorique&quot;), col = c(&quot;red&quot;, &quot;black&quot;), lty = 1)

plot(density(sampleMH$theta[-c(1:500)]), col = &quot;red&quot;, ylab = &quot;Densité de probabilité a posteriori&quot;, 
    xlab = expression(theta), main = &quot;Zoom&quot;)
curve(dbeta(x, 241945 + 1, 251527 + 1), from = 0, to = 1, n = 10000, add = TRUE)
legend(&quot;topright&quot;, c(&quot;M-H&quot;, &quot;théorique&quot;), col = c(&quot;red&quot;, &quot;black&quot;), lty = 1)

plot(sampleMH$alpha, type = &quot;h&quot;, xlab = &quot;Itération&quot;, ylab = &quot;Probabilité d&#39;acceptation&quot;, 
    ylim = c(0, 1), col = &quot;springgreen&quot;)
plot(sampleMH$theta, type = &quot;l&quot;, xlab = &quot;Itération&quot;, ylab = expression(paste(&quot;Valeur échantillonnée pour &quot;, 
    theta)), ylim = c(0, 1))</code></pre>
<p><img src="/practicals/03-MHQuestions_files/figure-html/MHcomp-1.png" width="768" /></p></li>
<li><p>Afin de mieux illustrer le fonctionnement de l’algorithme de Metropolis-Hastings, nous allons modifier la loi stationnaire cible de la chaîne de Markov en ne considérant que <span class="math inline">\(100\)</span> observations, parmi lequelles <span class="math inline">\(49\)</span> naissances sont des filles, et en changeant l’<em>a priori</em> pour une loi <span class="math inline">\(\text{Beta}(\alpha = 3, \beta=3)\)</span>.
Reprogrammer une fonction <code>post_num_beta()</code> calculant le numérateur de la loi <em>a posteriori</em> correspondante (d’après la formule vue dans le cours), puis faites tourner l’algorithme <code>monMH()</code> avec <span class="math inline">\(10\,000\)</span> itérations.<br />
NB : On conserve donc une loi instrumentale uniforme (celle-ci n’est obligatoirement égale à l’<em>a priori</em>). Si le temps le permet, utiliser également l’<em>a priori</em> <span class="math inline">\(\text{Beta}\)</span> pour la loi instrumentale.</p>
<pre class="r"><code>post_num_beta &lt;- function(theta, log = TRUE, a = 3, b = 3) {

    n &lt;- 100  # nombre d&#39;essais (naissances)
    S &lt;- 49  # nombre de succès (naissances féminines)

    if (log) {
        num &lt;- (a + S - 1) * (log(theta)) + (b + n - S - 1) * log(1 - theta)
    } else {
        num &lt;- theta^(a + S - 1) * (1 - theta)^(b + n - S - 1)
    }
    return(num)
}

sampleMH &lt;- monMH(10000, post_num = post_num_beta)

# evaluation graphique
par(mfrow = c(2, 2))
plot(density(sampleMH$theta[-c(1:500)]), col = &quot;red&quot;, xlim = c(0, 1), ylab = &quot;Densité de probabilité a posteriori&quot;, 
    xlab = expression(theta), main = &quot;&quot;)
curve(dbeta(x, 49 + 1, 51 + 1), from = 0, to = 1, add = TRUE)
legend(&quot;topright&quot;, c(&quot;M-H&quot;, &quot;théorique&quot;), col = c(&quot;red&quot;, &quot;black&quot;), lty = 1)
plot.new()
plot(sampleMH$alpha, type = &quot;h&quot;, xlab = &quot;Itération&quot;, ylab = &quot;Probabilité d&#39;acceptation&quot;, 
    ylim = c(0, 1), col = &quot;springgreen&quot;)
plot(sampleMH$theta, type = &quot;l&quot;, xlab = &quot;Itération&quot;, ylab = expression(paste(&quot;Valeur échantillonnée pour &quot;, 
    theta)), ylim = c(0, 1))</code></pre>
<p><img src="/practicals/03-MHQuestions_files/figure-html/MHbeta-1.png" width="768" /></p></li>
<li><p>Nous allons maintenant revenir à la loi stationnaire initiale utilisant les données de l’exemple historique avec un <em>a priori</em> uniforme.<br />
Programmer un algorithme de Metropolis-Hastings à marche aléatoire (on pourra commencer par prendre un pas aléatoire uniforme d’amplitude <span class="math inline">\(0,02\)</span>, puis (si le temps le permet) un pas gaussien d’écart-type <span class="math inline">\(0,02\)</span>). Étudier à nouveau les résultats ainsi obtenus (on pourra faire varier la taille du pas aléatoire).</p>
<pre class="r"><code>monMH_marchalea &lt;- function(niter, post_num, a=3, b=3){

  theta_save &lt;- numeric(length = niter)
  alpha &lt;- numeric(length = niter)

  #initialisation de theta
  theta &lt;- runif(n = 1, min = 0, max = 1)

  for(t in 1:niter){
    #proposer une valeur à partir de la loi instrumentale (marche aléatoire)
    theta_prop &lt;- theta + runif(1, -0.01, 0.01) #rnorm(1, mean = 0, sd = 0.02)

    #calculer la probabilité d&#39;acceptation-rejet
    alpha[t] &lt;- min(1, exp(post_num(theta_prop, log=TRUE) - 
                           post_num(theta, log=TRUE)))

    #étape d&#39;acceptation-rejet
    u &lt;- runif(1)
    if(u &lt;= alpha[t]){
      theta &lt;- theta_prop # accept theta_prop and update current value
    }

    #sauvegrade de la valeur courante de theta
    theta_save[t] &lt;- theta
  }

  return(list(&quot;theta&quot; = theta_save, &quot;alpha&quot; = alpha))
}

sampleMH &lt;- monMH_marchalea(20000, post_num = post_num_hist)


par(mfrow=c(2,2))
plot(density(sampleMH$theta[-c(1:1000)]), col = &quot;red&quot;, #xlim=c(0,1),
     ylab = &quot;Densité de probabilité a posteriori&quot;, 
     xlab=expression(theta), main = &quot;Zoom&quot;)
curve(dbeta(x, 241945 + 1, 251527+1), from = 0, to = 1, n = 10000, add = TRUE)
legend(&quot;topright&quot;, c(&quot;M-H&quot;, &quot;théorique&quot;), col = c(&quot;red&quot;, &quot;black&quot;), lty = 1)
plot(sampleMH$alpha, type = &quot;h&quot;, xlab = &quot;Itération&quot;, 
     ylab = &quot;Probabilité d&#39;acceptation&quot;, ylim = c(0,1), col = &quot;springgreen&quot;)
plot(sampleMH$theta, type=&quot;l&quot;, xlab = &quot;Itération&quot;, 
     ylab = expression(paste(&quot;Valeur échantillonnée pour &quot;, theta)), ylim = c(0,1))
plot(sampleMH$theta, type=&quot;l&quot;, xlab = &quot;Itération&quot;, main = &quot;Zoom&quot;,
     ylab = expression(paste(&quot;Valeur échantillonnée pour &quot;, theta)), ylim = c(0.45, 0.55))</code></pre>
<p><img src="/practicals/03-MHQuestions_files/figure-html/MHalea-1.png" width="768" /></p></li>
</ol>
